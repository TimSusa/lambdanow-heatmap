# Task
task.class=com.lambdanow.heatmap.task.Analyse
task.inputs=kafka.points
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
# Normally, this would be 3, but we have only one broker.
task.checkpoint.replication.factor=1

# YARN
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=points_processor
# hdfs://NAMENODE-NODE-INTERNAL-DNS-NAME:8020/user/ubuntu/*-dist.tar.gz
yarn.package.path=hdfs://ip-172-31-52-59.ec2.internal:8020/user/ubuntu/lambdanow-heatmap-1.0-SNAPSHOT-dist.tar.gz

schema.registry.remote=true
# http://DATA-API-INTERNAL-DNS-NAME:8080/1/schemas/
schema.registry.url=http://ip-172-31-50-115.ec2.internal:8080/1/schemas/

# <DATA-API-TOKEN>
schema.registry.token=13357cf552

# Serializers
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.avro.class=com.lambdanow.heatmap.serializer.AvroRecordFactory

systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=avro
# systems.kafka.consumer.zookeeper.connect=<KAFKA1-NODE-INTERNAL-DNS-NAME>:2181,<KAFKA2-NODE-INTERNAL-DNS-NAME>:2181,<KAFKA3-NODE-INTERNAL-DNS-NAME>:2181
# systems.kafka.producer.bootstrap.servers=<KAFKA1-NODE-INTERNAL-DNS-NAME>:9092,<KAFKA2-NODE-INTERNAL-DNS-NAME>:9092,<KAFKA3-NODE-INTERNAL-DNS-NAME>:9092
systems.kafka.consumer.zookeeper.connect=ip-172-31-54-150.ec2.internal:2181,ip-172-31-54-151.ec2.internal:2181,ip-172-31-54-152.ec2.internal:2181
systems.kafka.producer.bootstrap.servers=ip-172-31-54-150.ec2.internal:9092,ip-172-31-54-151.ec2.internal:9092,ip-172-31-54-152.ec2.internal:9092

#stores.points-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
#stores.points-store.changelog=kafka.points-store-changelog
#stores.points-store.key.serde=string
#stores.points-store.msg.serde=integer